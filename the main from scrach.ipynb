{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "502acbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f441f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter2d(image ,kernel):\n",
    "    height, width, channels = image.shape\n",
    "    k_height, k_width = kernel.shape[:2]\n",
    "    \n",
    "    pad_height = k_height // 2\n",
    "    pad_width = k_width // 2\n",
    "    \n",
    "    output_image = np.zeros((height, width, channels), dtype=np.uint8)\n",
    "    \n",
    "    for c in range(channels):\n",
    "        for i in range(pad_height, height - pad_height):\n",
    "            for j in range(pad_width, width - pad_width):\n",
    "                neighborhood = image[i - pad_height:i + pad_height + 1, j - pad_width:j + pad_width + 1, c]\n",
    "                filtered_pixel = np.sum(neighborhood * kernel)\n",
    "                output_image[i, j, c] = filtered_pixel\n",
    "    \n",
    "    return output_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12897eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(image, kernel_size=5, sigma=1.5):\n",
    "\n",
    "    # Check if the image is loaded successfully\n",
    "    if image is None:\n",
    "        print(\"Error: Unable to read the image.\")\n",
    "        return None\n",
    "\n",
    "    # Convert the image to float32 for numerical stability\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Create a Gaussian kernel\n",
    "    kernel = np.fromfunction(\n",
    "        lambda x, y: (1 / (2 * np.pi * sigma ** 2)) *\n",
    "                    np.exp(-((x - kernel_size // 2) ** 2 + (y - kernel_size // 2) ** 2) / (2 * sigma ** 2)),\n",
    "        (kernel_size, kernel_size)\n",
    "    )\n",
    "\n",
    "    # Normalize the kernel\n",
    "    kernel = kernel / kernel.sum()\n",
    "\n",
    "    # Apply the Gaussian blur by convolving the image with the kernel\n",
    "    blurred_image = filter2d(image, kernel)\n",
    "\n",
    "    # Convert back to uint8 for display\n",
    "    blurred_image = blurred_image.astype(np.uint8)\n",
    "\n",
    "    return blurred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db46a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_operator(image):\n",
    "    # Sobel kernels\n",
    "    sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "\n",
    "    # Convolve the image with Sobel kernels\n",
    "    gradient_x = convolve(image, sobel_x)\n",
    "    gradient_y = convolve(image, sobel_y)\n",
    "\n",
    "    # Compute gradient magnitude and direction\n",
    "    gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "    gradient_direction = np.arctan2(gradient_y, gradient_x)\n",
    "\n",
    "    return gradient_magnitude, gradient_direction\n",
    "\n",
    "def convolve(image, kernel):\n",
    "    height, width = image.shape\n",
    "    k_height, k_width = kernel.shape\n",
    "\n",
    "    # Calculate the padding to handle the kernel size\n",
    "    pad_height = k_height // 2\n",
    "    pad_width = k_width // 2\n",
    "\n",
    "    # Create an empty output image\n",
    "    output_image = np.zeros((height, width))\n",
    "\n",
    "    # Iterate over the input image and apply convolution\n",
    "    for i in range(pad_height, height - pad_height):\n",
    "        for j in range(pad_width, width - pad_width):\n",
    "            neighborhood = image[i - pad_height:i + pad_height + 1, j - pad_width:j + pad_width + 1]\n",
    "            output_image[i, j] = np.sum(neighborhood * kernel)\n",
    "\n",
    "    return output_image\n",
    "\n",
    "def canny_edge_detection(image, low_threshold, high_threshold):\n",
    "\n",
    "    # Step 2: Compute gradient using Sobel operators\n",
    "    gradient_magnitude, gradient_direction = sobel_operator(image)\n",
    "\n",
    "    # Step 3: Non-maximum suppression\n",
    "    suppressed_image = non_maximum_suppression(gradient_magnitude, gradient_direction)\n",
    "\n",
    "    # Step 4: Edge tracking by hysteresis\n",
    "    edges = hysteresis_thresholding(suppressed_image, low_threshold, high_threshold)\n",
    "\n",
    "    return edges.astype(np.uint8) * 255\n",
    "\n",
    "def non_maximum_suppression(magnitude, direction):\n",
    "    height, width = magnitude.shape\n",
    "    suppressed = np.zeros_like(magnitude)\n",
    "\n",
    "    for i in range(1, height - 1):\n",
    "        for j in range(1, width - 1):\n",
    "            angle = direction[i, j]\n",
    "\n",
    "            # Define gradient directions\n",
    "            grad_dir = (0 if (angle < np.pi / 8) or (angle >= 7 * np.pi / 8) else\n",
    "                        1 if (angle >= np.pi / 8) and (angle < 3 * np.pi / 8) else\n",
    "                        2 if (angle >= 3 * np.pi / 8) and (angle < 5 * np.pi / 8) else\n",
    "                        3)\n",
    "\n",
    "            # Perform non-maximum suppression\n",
    "            if grad_dir == 0:\n",
    "                neighbors = (magnitude[i, j - 1], magnitude[i, j + 1])\n",
    "            elif grad_dir == 1:\n",
    "                neighbors = (magnitude[i - 1, j - 1], magnitude[i + 1, j + 1])\n",
    "            elif grad_dir == 2:\n",
    "                neighbors = (magnitude[i - 1, j], magnitude[i + 1, j])\n",
    "            else:\n",
    "                neighbors = (magnitude[i - 1, j + 1], magnitude[i + 1, j - 1])\n",
    "\n",
    "            suppressed[i, j] = magnitude[i, j] if magnitude[i, j] >= max(neighbors) else 0\n",
    "\n",
    "    return suppressed\n",
    "\n",
    "def hysteresis_thresholding(image, low_threshold, high_threshold):\n",
    "    strong_edges = (image >= high_threshold)\n",
    "    weak_edges = (image >= low_threshold) & (image < high_threshold)\n",
    "\n",
    "    # Perform edge tracking by hysteresis\n",
    "    for i in range(1, image.shape[0] - 1):\n",
    "        for j in range(1, image.shape[1] - 1):\n",
    "            if weak_edges[i, j]:\n",
    "                # Check if any of the 8 neighboring pixels is a strong edge\n",
    "                if np.any(strong_edges[i-1:i+2, j-1:j+2]):\n",
    "                    strong_edges[i, j] = True\n",
    "                else:\n",
    "                    weak_edges[i, j] = False\n",
    "\n",
    "    return strong_edges.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d659eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab8975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2b43f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def resize_frame(frame, scale_percent):\n",
    "    width = int(frame.shape[1] * scale_percent / 100)\n",
    "    height = int(frame.shape[0] * scale_percent / 100)\n",
    "    return cv2.resize(frame, (width, height))\n",
    "\n",
    "# Load the video\n",
    "video = cv2.VideoCapture(r'C:\\Users\\kapitoo\\Downloads\\feter_meshaltet.mp4')\n",
    "\n",
    "# Get the video properties (width, height, frames per second)\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Changed to mp4\n",
    "out = cv2.VideoWriter(r'C:\\Users\\kapitoo\\Downloads\\output_video.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "while True:\n",
    "    ret, orig_frame = video.read()\n",
    "\n",
    "    if not ret:\n",
    "        video = cv2.VideoCapture(r'C:\\Users\\kapitoo\\Downloads\\feter_meshaltet.mp4')\n",
    "        continue\n",
    "\n",
    "    # Resize frame for faster processing\n",
    "    scale_percent = 50  # Adjust as needed\n",
    "    frame = resize_frame(orig_frame, scale_percent)\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "\n",
    "    # Convert frame to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Adjusted HSV values for yellow\n",
    "    low_yellow = np.array([15, 50, 150])\n",
    "    up_yellow = np.array([35, 255, 255])\n",
    "\n",
    "    # Adjusted HSV values for white\n",
    "    low_white = np.array([0, 0, 200])\n",
    "    up_white = np.array([255, 30, 255])\n",
    "\n",
    "    # Create masks for yellow and white\n",
    "    mask_yellow = cv2.inRange(hsv, low_yellow, up_yellow)\n",
    "    mask_white = cv2.inRange(hsv, low_white, up_white)\n",
    "\n",
    "    # Combine the masks\n",
    "    combined_mask = cv2.bitwise_or(mask_yellow, mask_white)\n",
    "\n",
    "    # Set the region of interest (ROI) to a slightly lower portion of the image\n",
    "    height, width = frame.shape[:2]\n",
    "    roi_mask = np.zeros_like(combined_mask)\n",
    "    roi_mask[int(0.6 * height):height, :] = 255\n",
    "    combined_mask = cv2.bitwise_and(combined_mask, roi_mask)\n",
    "\n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(combined_mask, 50, 150)  # Adjust the thresholds\n",
    "\n",
    "    # Detect lines using Hough transform\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=50, maxLineGap=100)\n",
    "\n",
    "    # Draw lines on the frame\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "\n",
    "    # Write the frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Exit if the user presses 'q'\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoWriter and VideoCapture objects\n",
    "out.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a69e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
